# LDD Loop Designer

> 通过 AskUserQuestion 交互式访谈，让人类参与定义验证标准

## 设计原则

1. **人类定标准**：验证标准必须由人类确认，AI 不能自己定义"什么是好的"
2. **验证强度透明**：明确告知当前验证的可靠程度
3. **渐进式收集**：通过多轮 AskUserQuestion 逐步收集信息

---

## 流程概览

```
阶段 1: 界定（AskUserQuestion 1-2）
    ↓
阶段 2: 验证强度评估 → 弱验证时警告
    ↓
阶段 3: 验证标准设计（AskUserQuestion 3-4）
    ↓
阶段 4: 人类确认 L1 规则 + L2 红旗
    ↓
阶段 5: 生成 LOOP-DESIGN.md
```

---

## 阶段 1: 界定

### AskUserQuestion #1：目标与验证

```json
{
  "questions": [
    {
      "question": "你想优化什么类型的目标？",
      "header": "优化目标",
      "options": [
        { "label": "Prompt / 提示词", "description": "优化 AI 提示词的效果" },
        { "label": "代码模板", "description": "优化代码生成模板或配置" },
        { "label": "内容模板", "description": "优化文档、消息、响应模板" },
        { "label": "流程配置", "description": "优化工作流或自动化配置" }
      ],
      "multiSelect": false
    },
    {
      "question": "你有哪些方式来判断结果是否更好？（可多选）",
      "header": "验证方式",
      "options": [
        { "label": "硬指标", "description": "测试通过率、Schema校验、正则匹配等可自动化检查" },
        { "label": "外部信号", "description": "用户反馈、线上指标、A/B测试结果" },
        { "label": "人工抽检", "description": "定期人工审核输出质量" },
        { "label": "参考样本", "description": "有几个\"好结果\"的例子可以对比" }
      ],
      "multiSelect": true
    }
  ]
}
```

### 验证强度评估

根据 AskUserQuestion #1 的回答评估验证强度：

```
验证强度 =
  包含"硬指标" OR 包含"外部信号" → 强验证
  包含"人工抽检" OR 包含"参考样本" → 中验证
  都不包含 → 弱验证（仅 AI 评估）
```

**弱验证警告**：

如果验证强度为"弱"，必须向用户说明：

```
⚠️ 验证强度警告

你的验证方式仅依赖 AI 评估。这存在以下风险：
- AI 无法可靠判断主观质量
- 可能出现"分数涨了但实际变差"的情况
- 循环可能无法真正收敛

建议：
1. 增加硬指标（如格式校验、长度限制）
2. 准备 3-5 个参考样本
3. 承诺每轮人工抽检

是否继续？
```

### AskUserQuestion #2：投入与终止

```json
{
  "questions": [
    {
      "question": "你计划投入多少轮迭代？",
      "header": "迭代周期",
      "options": [
        { "label": "快速验证 (1-3轮)", "description": "快速测试想法，投入少" },
        { "label": "中度迭代 (5-10轮)", "description": "认真优化，有明确目标" },
        { "label": "持续优化", "description": "长期运行，持续改进" }
      ],
      "multiSelect": false
    },
    {
      "question": "什么情况下算\"完成\"？",
      "header": "终止条件",
      "options": [
        { "label": "达到质量标准", "description": "L1全通过 + 无红旗 + 人工确认OK" },
        { "label": "固定轮数", "description": "跑完 N 轮就停止" },
        { "label": "连续无提升", "description": "连续 3 轮没有改进就停止" },
        { "label": "我来决定", "description": "每轮结束后我决定是否继续" }
      ],
      "multiSelect": false
    }
  ]
}
```

---

## 阶段 2: 适合性判断

基于收集的信息判断是否适合 LDD：

| 条件 | 结论 |
|------|------|
| 验证强度=强 | ✅ 适合，可高度自动化 |
| 验证强度=中 | ⚠️ 适合，但需要定期人工参与 |
| 验证强度=弱 + 用户确认继续 | ⚠️ 可尝试，每轮需人工确认 |
| 验证强度=弱 + 用户放弃 | ❌ 退出，建议手动迭代 |

---

## 阶段 3: 验证标准设计

### AskUserQuestion #3：L1 硬验证规则

```json
{
  "questions": [
    {
      "question": "输出必须满足哪些硬性条件？（可多选）",
      "header": "硬验证规则",
      "options": [
        { "label": "格式正确", "description": "JSON/Markdown/特定结构" },
        { "label": "必填字段", "description": "某些字段必须存在" },
        { "label": "长度限制", "description": "字符数/行数在范围内" },
        { "label": "无敏感信息", "description": "不包含密码/路径/堆栈" }
      ],
      "multiSelect": true
    }
  ]
}
```

**追问细节**：

根据用户选择，用文本追问具体规则：
- 格式正确 → "请描述期望的格式，例如 JSON Schema"
- 必填字段 → "哪些字段必须存在？"
- 长度限制 → "最小/最大长度是多少？"

### AskUserQuestion #4：L2 红旗规则

```json
{
  "questions": [
    {
      "question": "哪些情况应该触发红旗，提示可能有问题？（可多选）",
      "header": "红旗规则",
      "options": [
        { "label": "内容模糊", "description": "表述不清晰、不具体" },
        { "label": "缺少关键信息", "description": "遗漏了应该包含的内容" },
        { "label": "语气不当", "description": "过于随意/过于正式/不专业" },
        { "label": "逻辑问题", "description": "自相矛盾或不合理" }
      ],
      "multiSelect": true
    }
  ]
}
```

**重要说明**：

向用户解释 L2 的定位：

```
关于红旗检测：

L2 不会给输出打分，而是标记"明显有问题"的情况。
- 如果检测到红旗 → 暂停，请你审核
- 如果没有红旗 → 继续，但不代表"好"

"好不好"的判断由你通过抽检来做（L3）。
AI 只帮你过滤掉明显的坏结果。
```

---

## 阶段 4: 锚定样本

### 请求锚定样本

```
请提供 3-5 个参考样本：

好样本（2-3个）：你认为质量好的输出
- 说明为什么好

坏样本（1-2个）：你认为质量差的输出
- 说明为什么差

这些样本用于：
1. 校准 L2 红旗检测（坏样本应该触发红旗）
2. 作为抽检时的对比基准
```

### 无锚定样本的处理

如果用户无法提供：

```
⚠️ 无锚定样本

没有参考样本意味着：
- L2 红旗检测可能不准确
- 无法判断优化方向是否正确

建议：
1. 先运行 1-2 轮，从输出中挑选好坏样本
2. 每轮都进行人工审核

是否继续？
```

---

## 阶段 5: 生成 LOOP-DESIGN.md

```markdown
# {项目名} Loop 设计

## 概览

| 项目 | 值 |
|------|-----|
| 优化目标 | {Q1 回答} |
| 验证强度 | {强/中/弱} |
| 迭代周期 | {Q2 回答} |
| 终止条件 | {Q2 回答} |
| 抽检频率 | {根据验证强度} |

## 验证标准（人类确认）

### L1 硬验证
{基于 Q3 的规则列表}

- [ ] 规则 1
- [ ] 规则 2
- ...

### L2 红旗检测
{基于 Q4 的红旗列表}

触发以下任一条件时标记红旗：
- [ ] 红旗 1
- [ ] 红旗 2
- ...

**L2 输出格式**：
```json
{
  "flags": ["flag_name"],
  "severity": "warning" | "critical",
  "needsHumanReview": true
}
```

### L3 人类校准

锚定样本：
- 好样本：{数量} 个
- 坏样本：{数量} 个

抽检频率：每 {N} 轮

## 人类参与点

| 时机 | 行为 |
|------|------|
| L2 触发红旗 | 审核输出，决定是否继续 |
| 每 {N} 轮 | 抽检，评估当前质量 |
| 连续无提升 | 决定是否调整方向或终止 |

## 文件清单

- [ ] target.* - 被优化目标
- [ ] executor.* - 执行器
- [ ] verifier.* - 验证器
- [ ] anchors/ - 锚定样本
```

---

## 术语对照

| LDD 术语 | 通俗说法 |
|----------|----------|
| L1 硬验证 | 自动检查（格式、字段、长度） |
| L2 红旗检测 | AI 帮你发现明显问题 |
| L3 人类校准 | 你自己看看好不好 |
| 锚定样本 | "好结果"和"坏结果"的例子 |
| 验证强度 | 验证有多可靠 |

---

## 常见问题

### Q: 为什么 L2 不打分？

A: AI 无法可靠判断主观质量。如果 AI 能准确评分，它应该能直接生成高分输出。L2 只标记"明显的问题"，把精确判断留给人类。

### Q: 验证强度"弱"能用吗？

A: 可以尝试，但需要每轮人工确认。弱验证的 Loop 本质上是"AI 建议 + 人类决策"，自动化程度低。

### Q: 没有锚定样本怎么办？

A: 可以先运行 1-2 轮，从输出中挑选。但前几轮需要更频繁的人工审核。

---

## 版本历史

### v2.0（当前）
- 集成 AskUserQuestion 交互式访谈
- 增加验证强度评估和警告
- L2 重新定位为红旗检测
- 增加人类参与点说明

### v1.0
- 初始版本
- 问题：AI 自主决策过多，人类参与不足
